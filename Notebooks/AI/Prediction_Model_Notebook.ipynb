{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a7d27c8-91d1-4d68-bf5c-5e4231352c4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61eb90d3-abd1-4a9e-a1a8-7bcc1843c304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(\"Current run ID:\", run_id)\n",
    "\n",
    "\n",
    "# Get artifact URI for the run\n",
    "run = client.get_run(run_id)\n",
    "artifact_uri = run.info.artifact_uri\n",
    "\n",
    "print(\"Artifact URI for run:\", artifact_uri)\n",
    "\n",
    "\n",
    "experiment_name = \"/Users/bharatshruti02@gmail.com/vehicle_sales_prediction_model\"\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "runs = client.search_runs(experiment_id, order_by=[\"attributes.start_time DESC\"], max_results=1)\n",
    "if runs:\n",
    "    run_id = runs[0].info.run_id\n",
    "    print(\"Most recent run id:\", run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4864f708-4158-4af5-9a47-99a98ae10a56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the credentials from the table you uploaded\n",
    "creds_df = spark.table(\"delta_lake.default.shruti_hackathon_access_keys\")\n",
    "creds_df.show()  # For debugging: see the structure\n",
    "\n",
    "# Extract credentials as local Python variables\n",
    "creds_row = creds_df.first()\n",
    "access_key = creds_row['Access key ID']\n",
    "secret_key = creds_row['Secret access key']\n",
    "\n",
    "print(\"Access Key:\", access_key)\n",
    "print(\"Secret Key:\", secret_key)\n",
    "\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Create a session with the extracted credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key\n",
    ")\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "bucket = s3.Bucket('smart-enterprise-modernization-data')\n",
    "\n",
    "# List objects as a test\n",
    "for obj in bucket.objects.all():\n",
    "    print(obj.key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69471c4f-3123-4079-b1af-faacea32861e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Read and prepare data\n",
    "gold_df = spark.table(\"enterprise_modernization.gold.customer_vehicle_fleet\")\n",
    "features = [\"price\", \"engine_size\", \"mileage\", \"fault_count\", \"avg_odometer\"]\n",
    "target = \"sales\"\n",
    "gold_pd = gold_df.select(features + [target]).dropna().toPandas()\n",
    "gold_pd[features] = gold_pd[features].astype(float)\n",
    "X = gold_pd[features]\n",
    "y = gold_pd[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test MSE: {mse:.2f}\")\n",
    "print(f\"Test R^2 Score: {r2:.2f}\")\n",
    "\n",
    "# Set experiment with S3 artifact location (do this once)\n",
    "experiment_name = \"/Users/bharatshruti02@gmail.com/vehicle_sales_prediction\"\n",
    "artifact_location = \"dbfs:/Volumes/enterprise_modernization/silver/mlflow_artifacts/\"\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "if not experiment:\n",
    "    mlflow.create_experiment(\n",
    "        name=experiment_name,\n",
    "        artifact_location=artifact_location\n",
    "    )\n",
    "\n",
    "mlflow.set_experiment(\"/Users/bharatshruti02@gmail.com/vehicle_sales_prediction_model\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\", input_example = X_train.head(10).to_dict(orient='records')[0])\n",
    "\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    # Register model in Model Registry (versioning is automatic)\n",
    "    result = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run.info.run_id}/random_forest_model\",\n",
    "        name=\"vehicle_sales_prediction_model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c051278a-0ea9-41e9-9a42-1d6d7c0495b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# client = MlflowClient()\n",
    "\n",
    "# with mlflow.start_run() as run:\n",
    "#     run_id = run.info.run_id\n",
    "#     print(\"Current run ID:\", run_id)\n",
    "\n",
    "# run = client.get_run(run_id)\n",
    "# artifact_uri = run.info.artifact_uri  \n",
    "\n",
    "# model_path_in_dbfs = f\"{artifact_uri}/random_forest_model\"\n",
    "# print(\"Model path in DBFS:\", model_path_in_dbfs)\n",
    "\n",
    "# # Destination S3 path\n",
    "# s3_path = \"s3://smart-enterprise-modernization-data/ML_Model_Output/vehicle_sales_prediction_model/\"\n",
    "\n",
    "# # Copy artifact folder from DBFS to S3\n",
    "# dbutils.fs.cp(model_path_in_dbfs, s3_path, recurse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3863aa62-6a29-48b6-9c63-5d63bd04dc10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "\n",
    "model_name = \"vehicle_sales_prediction_model\"\n",
    "model_version = 1\n",
    "\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Load new data\n",
    "new_data_df = spark.read.table(\"enterprise_modernization.gold.customer_vehicle_fleet\")\n",
    "\n",
    "selected_features = [\"price\", \"engine_size\", \"mileage\", \"fault_count\", \"avg_odometer\"]\n",
    "\n",
    "input_df = (new_data_df.select(selected_features).toPandas().dropna().astype(float))\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(input_df)\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions, columns=[\"predicted_sales\"])\n",
    "\n",
    "display(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a64a5d7-6155-454b-8f58-c9421df486b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "instance_url = dbutils.secrets.get(\"my_scope\", \"databricks_instance_url\").rstrip(\"/\")\n",
    "pat_token = dbutils.secrets.get(\"my_scope\", \"databricks_pat_token\")\n",
    "endpoint_name = \"vehicle_sales_prediction_endpoint\"\n",
    "\n",
    "endpoint_url = f\"{instance_url}/serving-endpoints/{endpoint_name}/invocations\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {pat_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "\n",
    "input_df = (new_data_df.select(features).toPandas().dropna().astype(float))\n",
    "\n",
    "if not input_df.empty:\n",
    "    payload = {\"dataframe_records\": input_df.to_dict(orient=\"records\")}\n",
    "    response = requests.post(\n",
    "        endpoint_url,\n",
    "        headers=headers,\n",
    "        data=json.dumps(payload)\n",
    "    )\n",
    "    predictions = response.json()\n",
    "    display(predictions)\n",
    "else:\n",
    "    print(\"Input data is empty. No predictions to display.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b2bbb7d-543c-460f-aaf9-e44394a0655a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "\n",
    "# Load the MLflow model\n",
    "model_name = \"vehicle_sales_prediction_model\"\n",
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "st.title(\"Vehicle Sales Prediction\")\n",
    "\n",
    "st.write(\"Enter the values for the features below:\")\n",
    "\n",
    "# Define inputs for features\n",
    "price = st.number_input(\"Price\", min_value=0.0, format=\"%.2f\", step=1000.0)\n",
    "engine_size = st.number_input(\"Engine Size\", min_value=0.0, format=\"%.2f\", step=0.1)\n",
    "mileage = st.number_input(\"Mileage\", min_value=0.0, format=\"%.2f\", step=100.0)\n",
    "fault_count = st.number_input(\"Fault Count\", min_value=0, step=1)\n",
    "avg_odometer = st.number_input(\"Avg Odometer\", min_value=0.0, format=\"%.2f\", step=1000.0)\n",
    "\n",
    "# When user clicks 'Predict', run prediction\n",
    "if st.button(\"Predict\"):\n",
    "    # Build a dataframe for the input to the model\n",
    "    input_df = pd.DataFrame({\n",
    "        \"price\": [price],\n",
    "        \"engine_size\": [engine_size],\n",
    "        \"mileage\": [mileage],\n",
    "        \"fault_count\": [fault_count],\n",
    "        \"avg_odometer\": [avg_odometer]\n",
    "    })\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(input_df)[0]\n",
    "\n",
    "    st.success(f\"Predicted Vehicle Sales: {prediction:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "258d8d38-89aa-481e-a3a6-dd492101346f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "streamlit run /databricks/python_shell/scripts/db_ipykernel_launcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee98f1f6-9e7e-4fbc-9754-1e08ffdd7516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466fa484-e7f0-4d48-ad27-e36262100a92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Prediction_Model_Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
